# -*- coding: utf-8 -*-
"""Project2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1za-o_QPdDog91ZcxFa6aCHB6GqVlyiwj
"""

import tensorflow as tf
import tensorflow.keras as keras
from tensorflow.keras.datasets import mnist
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense,Dropout
from tensorflow.keras.optimizers import RMSprop
import scipy.io as sio
from sklearn.preprocessing import OneHotEncoder as ohe
import numpy as np
print(tf.__version__)
print(keras.__version__)

filename = 'emnist-letters.mat'
mat_data = sio.loadmat(filename)
data = mat_data['dataset']

batch_size = 128
num_classes = 26
epochs = 10

X_train = data['train'][0,0]['images'][0,0]
y_train = data['train'][0,0]['labels'][0,0]
X_test = data['test'][0,0]['images'][0,0]
y_test = data['test'][0,0]['labels'][0,0]

Y_train = np.array(y_train)-1
Y_test = np.array(y_test)-1
Y_train = keras.utils.to_categorical(Y_train)
Y_test = keras.utils.to_categorical(Y_test)

model = Sequential()
model.add(Dense(700, activation='relu', input_shape=(784,)))
model.add(Dropout(0.2))
model.add(Dense(700, activation='relu'))
model.add(Dropout(0.2))
model.add(Dense(num_classes, activation='softmax'))

model.summary()

model.compile(loss='categorical_crossentropy',
              optimizer=RMSprop(),
              metrics=['accuracy'])

history = model.fit(X_train, Y_train,
                    batch_size=batch_size,
                    epochs=epochs,
                    verbose=1,
                    validation_data=(X_test, Y_test))
score = model.evaluate(X_test, Y_test, verbose=0)
print('Test loss:', score[0])
print('Test accuracy:', score[1])

